from typing import Any, Type

from pydantic import BaseModel
from sqlalchemy.exc import IntegrityError
from sqlalchemy.ext.declarative import DeclarativeMeta
from sqlalchemy.inspection import inspect
from sqlalchemy.orm import Session

from scrap.database import get_session
from scrap.dto.dto import DTO
from scrap.entities.entity import Entity
from scrap.repositories.exc import ObjectExists, ObjectNotExists
from scrap.repositories.repository import Repository


class SqlalchemyRepository[
    PK: Any, Entity_: Entity, CreateDTO: DTO, UpdateDTO: DTO
](
    Repository[PK, CreateDTO, UpdateDTO, Entity_]
):
    """Base repository managed by sqlalchemy.

    Attributes:
        sa_model: Sqlalchemy model class.
        entity_py_model: Entity (pydantic) class.

    """
    sa_model: Type[DeclarativeMeta]
    entity_py_model: Type[Entity_]

    def _get(
            self, pk: PK, session: Session
    ) -> DeclarativeMeta | None:
        return session.get(self.sa_model, pk)

    def _update_fields_by_schema(
            self, db_object: DeclarativeMeta, schema: BaseModel
    ) -> None:
        update_properties = schema.model_dump(mode="json", exclude_unset=True)
        for field, value in update_properties.items():
            setattr(db_object, field, value)

    def _update(
            self,
            pk: Any,
            schema: BaseModel,
            session: Session,
    ) -> BaseModel:
        db_object = self._get(pk, session)
        if db_object is None:
            raise ObjectNotExists(missin_pk=pk)
        self._update_fields_by_schema(db_object, schema)
        session.commit()
        return self.entity_py_model.model_validate(db_object)

    def _create_from_schema(
            self, schema: BaseModel, session: Session
    ) -> DeclarativeMeta:
        db_object = self.sa_model(**schema.model_dump(mode="json"))
        session.add(db_object)
        try:
            session.commit()
        except IntegrityError:
            raise ObjectExists
        return db_object

    def _create(self, schema: BaseModel, session: Session) -> BaseModel:
        db_object = self._create_from_schema(schema, session)
        return self.entity_py_model.model_validate(db_object)

    def _create_or_update(
            self,
            pk: PK,
            schema: BaseModel,
            session: Session,
    ) -> tuple[BaseModel, bool]:
        """Creates or updates an object.

        Args:
            pk: Primary key of the object.
            schema: Create or update DTO schema.
            session: SQLAlchemy session.

            Returns:
                Entity and `is_created` flag.
        """
        db_object = self._get(pk, session)
        if db_object is None:
            return self._create(schema, session), True
        return self._update(pk, schema, session), False

    def _bulk_upsert(
            self, schemas: list[BaseModel], session: Session
    ) -> list[BaseModel]:
        """Bulk upsert objects from a list of schemas.

        TODO: Find a way to use upsert (update on conflict).

        Args:
            schemas: List of CreateDTO schemas.
            session: SQLAlchemy session.

        Returns:
            List of created or updated entity instances.
        """
        pk = inspect(self.sa_model).primary_key
        if len(pk) == 1:
            pk = pk[0]
        else:
            raise NotImplementedError(
                "Bulk upsert isn't implemented for tables with composite PKs"
            )

        ids = [schema.id for schema in schemas]
        existing_query = session.query(self.sa_model).filter(pk.in_(ids))
        existing_dict = {obj.id: obj for obj in existing_query}

        entities = []

        for schema in schemas:
            if db_object := existing_dict.get(schema.id):
                self._update_fields_by_schema(db_object, schema)
                entities.append(self.entity_py_model.model_validate(db_object))
            else:
                db_object = self.sa_model(**schema.model_dump(mode="json"))
                session.add(db_object)
                # NOTE: Autogenerated column values by DBMS
                # isn't initialized on this stage.
                entities.append(self.entity_py_model.model_validate(db_object))
        session.commit()
        return entities

    def get(self, pk: PK) -> Entity_ | None:
        with get_session() as session:
            return self._get(pk, session)

    def create(self, create_data: CreateDTO) -> Entity_:
        with get_session() as session:
            self._create(create_data, session)

    def update(self, pk: PK, update_data: UpdateDTO) -> Entity_:
        with get_session() as session:
            return self._update(pk, update_data, session)

    def create_or_update(self, create_data: CreateDTO) -> tuple[Entity_, bool]:
        """Creates or updates an object.

        Args:
            create_data: Create DTO.

            Returns:
                Entity and `is_created` flag.
        """
        with get_session() as session:
            return self._create_or_update(
                create_data.id, create_data, session
            )

    def bulk_upsert(self, create_data_list: list[CreateDTO]) -> list[Entity_]:
        """Bulk upsert objects.

        Args:
            create_data_list: List of CreateDTOs.

        Returns:
            List of created or updated entity instances.

        Raises:
            NotImplementedError: For tables with composite PKs.
        """
        with get_session() as session:
            return self._bulk_upsert(create_data_list, session)
